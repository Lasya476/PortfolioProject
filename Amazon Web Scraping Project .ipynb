{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fadc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for web scraping, data handling, and email notifications\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "import schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aebdf4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html><head><style>body{background-color:transparent;margin:0;padding:0}</style></head><body> <script src=\"sf-1.50.ee33ade7.js\" ></script></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Connect to the website and retrieve content\n",
    "\n",
    "iframe_url = \"https://images-na.ssl-images-amazon.com/images/S/apesafeframe/ape/sf/desktop/sf-1.50.d19bd989.html\"\n",
    "response = requests.get(iframe_url)\n",
    "\n",
    "if response.ok:\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(\"Failed to retrieve content\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a46709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a488dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.9)\n",
      "Collecting websocket-client~=1.8\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 25.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing_extensions~=4.9\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
      "\u001b[K     |████████████████████████████████| 475 kB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/lib/python3.9/site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Collecting sniffio>=1.3.0\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting attrs>=23.2.0\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 6.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: attrs, sniffio, outcome, h11, exceptiongroup, wsproto, trio, websocket-client, typing-extensions, trio-websocket, selenium\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.4.0\n",
      "    Uninstalling attrs-21.4.0:\n",
      "      Successfully uninstalled attrs-21.4.0\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 0.58.0\n",
      "    Uninstalling websocket-client-0.58.0:\n",
      "      Successfully uninstalled websocket-client-0.58.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.1.1\n",
      "    Uninstalling typing-extensions-4.1.1:\n",
      "      Successfully uninstalled typing-extensions-4.1.1\n",
      "Successfully installed attrs-24.2.0 exceptiongroup-1.2.2 h11-0.14.0 outcome-1.3.0.post0 selenium-4.25.0 sniffio-1.3.1 trio-0.26.2 trio-websocket-0.11.1 typing-extensions-4.12.2 websocket-client-1.8.0 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Use Selenium to open the Amazon page and locate product details like title and price\n",
    "# Used this method because the product title and price were in inframe. that couldn't be retreived by beautifulsoup\n",
    "pip install selenium  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "002287a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon.com: Funny Got Data MIS Data Systems Business Analyst T-Shirt : Clothing, Shoes & Jewelry\n"
     ]
    }
   ],
   "source": [
    "# Start Safari WebDriver\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "# Go to a website\n",
    "driver.get('https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_1_sspa?crid=38ZS4MALBH57R&dib=eyJ2IjoiMSJ9.E-H5Z9cAvFvKSM510n9CcAQS0RFsUzX6p0rqnNeAYOA_-QGne7A5Yj_2ogulbviC68EEH8v92R5Fu79mqc2HBKNDjwvz_MCLd_0HtU14TA69toLxJKeP-ayeqLu5Mx55JIgsWf4m5NsShJ6BIX0J6yBuB5wE61Fjj9LbxCcF7BVJt09vwO9xuwBgyt37AFsHPhjUg7LIcCD9F8_CgCgc3RduD4dnorE9GNSeXLsr8fROu7b9c5bqKf1T2IuirP8jOnJ47GCala1Lbai77SCzhjoU9bIa9FZGIsluBLG80ks.r0GmeWhQKR0onj_6v8d1Txiry-7OKCgnI0QE-aODPk8&dib_tag=se&keywords=data%2Banalyst%2Btshirt&qid=1728333098&sprefix=data%2Banalyst%2Caps%2C154&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1')\n",
    "\n",
    "# Print page title\n",
    "print(driver.title)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c78d6574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Funny Got Data MIS Data Systems Business Analyst T-Shirt       \n"
     ]
    }
   ],
   "source": [
    "# Start Safari WebDriver\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "# Go to the Amazon product page\n",
    "driver.get('https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_1_sspa?crid=38ZS4MALBH57R&dib=eyJ2IjoiMSJ9.E-H5Z9cAvFvKSM510n9CcAQS0RFsUzX6p0rqnNeAYOA_-QGne7A5Yj_2ogulbviC68EEH8v92R5Fu79mqc2HBKNDjwvz_MCLd_0HtU14TA69toLxJKeP-ayeqLu5Mx55JIgsWf4m5NsShJ6BIX0J6yBuB5wE61Fjj9LbxCcF7BVJt09vwO9xuwBgyt37AFsHPhjUg7LIcCD9F8_CgCgc3RduD4dnorE9GNSeXLsr8fROu7b9c5bqKf1T2IuirP8jOnJ47GCala1Lbai77SCzhjoU9bIa9FZGIsluBLG80ks.r0GmeWhQKR0onj_6v8d1Txiry-7OKCgnI0QE-aODPk8&dib_tag=se&keywords=data%2Banalyst%2Btshirt&qid=1728333098&sprefix=data%2Banalyst%2Caps%2C154&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1')\n",
    "\n",
    "# Locate the product title element\n",
    "product_title = driver.find_element(By.ID, \"productTitle\")\n",
    "\n",
    "# Print the product title text\n",
    "print(product_title.text)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c09f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c95cd294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: $16.99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start Safari WebDriver\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "# Go to the Amazon product page\n",
    "driver.get('https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_1_sspa?crid=38ZS4MALBH57R&dib=eyJ2IjoiMSJ9.E-H5Z9cAvFvKSM510n9CcAQS0RFsUzX6p0rqnNeAYOA_-QGne7A5Yj_2ogulbviC68EEH8v92R5Fu79mqc2HBKNDjwvz_MCLd_0HtU14TA69toLxJKeP-ayeqLu5Mx55JIgsWf4m5NsShJ6BIX0J6yBuB5wE61Fjj9LbxCcF7BVJt09vwO9xuwBgyt37AFsHPhjUg7LIcCD9F8_CgCgc3RduD4dnorE9GNSeXLsr8fROu7b9c5bqKf1T2IuirP8jOnJ47GCala1Lbai77SCzhjoU9bIa9FZGIsluBLG80ks.r0GmeWhQKR0onj_6v8d1Txiry-7OKCgnI0QE-aODPk8&dib_tag=se&keywords=data%2Banalyst%2Btshirt&qid=1728333098&sprefix=data%2Banalyst%2Caps%2C154&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1')\n",
    "\n",
    "# Locate the price element using By.XPATH\n",
    "try:\n",
    "    price_element = driver.find_element(By.XPATH, \"//span[@class='a-price']//span[@class='a-offscreen']\")\n",
    "    price = price_element.text\n",
    "    print(\"Price:\", price)\n",
    "except Exception as e:\n",
    "    print(\"Price element not found:\", e)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6bbcc2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title:         Funny Got Data MIS Data Systems Business Analyst T-Shirt       \n",
      "Price: $16.99\n"
     ]
    }
   ],
   "source": [
    "# Start Safari WebDriver\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "# Go to the Amazon product page\n",
    "driver.get('https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_1_sspa?crid=38ZS4MALBH57R&dib=eyJ2IjoiMSJ9.E-H5Z9cAvFvKSM510n9CcAQS0RFsUzX6p0rqnNeAYOA_-QGne7A5Yj_2ogulbviC68EEH8v92R5Fu79mqc2HBKNDjwvz_MCLd_0HtU14TA69toLxJKeP-ayeqLu5Mx55JIgsWf4m5NsShJ6BIX0J6yBuB5wE61Fjj9LbxCcF7BVJt09vwO9xuwBgyt37AFsHPhjUg7LIcCD9F8_CgCgc3RduD4dnorE9GNSeXLsr8fROu7b9c5bqKf1T2IuirP8jOnJ47GCala1Lbai77SCzhjoU9bIa9FZGIsluBLG80ks.r0GmeWhQKR0onj_6v8d1Txiry-7OKCgnI0QE-aODPk8&dib_tag=se&keywords=data%2Banalyst%2Btshirt&qid=1728333098&sprefix=data%2Banalyst%2Caps%2C154&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1')\n",
    "\n",
    "# Locate the product title element\n",
    "try:\n",
    "    product_title = driver.find_element(By.ID, \"productTitle\").text\n",
    "    print(\"Product Title:\", product_title)\n",
    "except Exception as e:\n",
    "    print(\"Product Title element not found:\", e)\n",
    "\n",
    "# Locate the price element using By.XPATH\n",
    "try:\n",
    "    price_element = driver.find_element(By.XPATH, \"//span[@class='a-price']//span[@class='a-offscreen']\")\n",
    "    price = price_element.text\n",
    "    print(\"Price:\", price)\n",
    "except Exception as e:\n",
    "    print(\"Price element not found:\", e)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e08feee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funny Got Data MIS Data Systems Business Analyst T-Shirt\n",
      "16.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_title = product_title.strip()\n",
    "price = price.strip()[1:]\n",
    "\n",
    "print(product_title)\n",
    "print(price)\n",
    "type(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec09f24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-07\n"
     ]
    }
   ],
   "source": [
    "today = datetime.date.today() \n",
    "\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4605bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Title', 'Price', 'Date']\n",
    "data = [product_title, price, today]\n",
    "\n",
    "#type(data) -- list\n",
    "\n",
    "with open('AmazonWebScrapingDataset.csv', 'w', newline = '', encoding = 'UTF8') as f: # 'w'is write, newline: it creates space ig\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18964bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Price        Date\n",
      "0  Funny Got Data MIS Data Systems Business Analy...  16.99  2024-10-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('/Users/lasya/AmazonWebScrapingDataset.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec52e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending Data to the CSV\n",
    "\n",
    "with open('AmazonWebScrapingDataset.csv', 'a+', newline = '', encoding = 'UTF8') as f: # a+: appends data\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a7a04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to automate the price check and scheduling it to run daily at a specified time\n",
    "\n",
    "# Define check_price function\n",
    "def check_price():\n",
    "    # Start Safari WebDriver\n",
    "    driver = webdriver.Safari()\n",
    "\n",
    "   # Locate the product title element\n",
    "    try:\n",
    "        product_title = driver.find_element(By.ID, \"productTitle\").text\n",
    "        print(\"Product Title:\", product_title)\n",
    "    except Exception as e:\n",
    "        print(\"Product Title element not found:\", e)\n",
    "\n",
    "# Locate the price element using By.XPATH\n",
    "    try:\n",
    "        price_element = driver.find_element(By.XPATH, \"//span[@class='a-price']//span[@class='a-offscreen']\")\n",
    "        price = price_element.text\n",
    "        print(\"Price:\", price)\n",
    "    except Exception as e:\n",
    "        print(\"Price element not found:\", e)\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "    \n",
    "    product_title = product_title.strip()\n",
    "    price = price.strip()[1:]\n",
    "\n",
    "    print(product_title)\n",
    "    print(price)\n",
    "\n",
    "    # Get today's date\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    # Prepare data to write\n",
    "    header = ['Title', 'Price', 'Date']\n",
    "    data = [product_title, price, today]\n",
    "\n",
    "    # Write to CSV \n",
    "    import csv \n",
    "\n",
    "    header = ['Title', 'Price', 'Date']\n",
    "    data = [product_title, price, today]\n",
    "\n",
    "    #type(data) -- list\n",
    "\n",
    "    with open('AmazonWebScrapingDataset.csv', 'w', newline = '', encoding = 'UTF8') as f: \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        writer.writerow(data)\n",
    "\n",
    "    # Append the data\n",
    "    with open('AmazonWebScrapingDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "    \n",
    "    # Load and print the data to verify\n",
    "    df = pd.read_csv('AmazonWebScrapingDataset.csv')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da6a3d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting schedule\n",
      "  Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: schedule\n",
      "Successfully installed schedule-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572cca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule the check_price function to run every day at a specific time (e.g., every day at 9 AM)\n",
    "import schedule \n",
    "schedule.every().day.at(\"09:00\").do(check_price)\n",
    "\n",
    "# Keep the script running to execute the scheduled tasks\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)  # Wait a minute before checking again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18dea3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Price        Date\n",
      "0  Funny Got Data MIS Data Systems Business Analy...  14.99  2024-10-07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/lasya/AmazonWebScrapingDataset.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365062f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send an email alert when the price falls below the desired threshold.\n",
    "\n",
    "import smtplib\n",
    "\n",
    "def send_mail():\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "    server.ehlo()\n",
    "    server.login('lasyapriya.devineni@gmail.com', '*******')\n",
    "    \n",
    "    subject = \"The Top you want is below $15! Now is your chance to buy!\"\n",
    "    body = \"Lasya, This is the moment we have been waiting for. Now is your chance to pick up thetop of your dreams. Don't mess it up! Link here: https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data+analyst+tshirt&qid=1626655184&sr=8-3\"\n",
    "   \n",
    "    msg = f\"Subject: {subject}\\n\\n{body}\"\n",
    "    \n",
    "    # Replace 'recipient@example.com' with the actual recipient's email address\n",
    "    server.sendmail(\n",
    "        'lasyapriya.devineni@gmail.com',  # From address\n",
    "        'lasyapriya.devineni@gmail.com',       # To address\n",
    "        msg                            # Message\n",
    "    )\n",
    "    \n",
    "    server.quit()  # Close the server\n",
    "\n",
    "# Example usage\n",
    "send_mail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d0189f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
